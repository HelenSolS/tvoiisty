# Идеи на будущее: рост AI-слоя (после подтверждения проекта)

Когда будет подтверждение на рост проекта — можно реализовать следующее. Сейчас (Issue #12) делаем минимально: одна ручка, без новых слоёв.

---

## Архитектура

- Выделить **отдельный AI-слой** (не только одна ручка): сервис вызова OpenAI с чёткими методами `analyzeGarment`, `buildTryOnPrompt`.
- Обёртка над OpenAI в `lib/ai/` (или аналог): переиспользуемая, типизированная, с единой обработкой ошибок и логированием.
- При добавлении других провайдеров (Vision, prompt-building) — общий контракт, не размазывать логику по ручкам.

## Масштабируемость

- Единая точка конфигурации моделей (gpt-4o, gpt-4o-mini и т.д.) и лимитов.
- При росте числа провайдеров — фасад/диспетчер, а не копипаста в каждом handler.

## Чистый код и типизация

- Zod-схемы уже есть (`lib/ai/garment-schema.ts`) — расширять на все ответы AI (не только garment JSON).
- Явные типы для запросов/ответов всех AI-ручек.
- Разделение: парсинг/валидация → бизнес-логика → ответ.

## Retry и fallback

- Retry с экспоненциальной задержкой и лимитом попыток (не только 1 retry Vision).
- Fallback-цепочки: например, при падении OpenAI — запасной путь (другой модель/провайдер или дефолтный промпт), без падения всего pipeline.
- Логирование причин fallback для мониторинга.

## Что уже сделано (Issue #12) и не трогаем сейчас

- Одна ручка `POST /api/prepare-tryon-prompt`.
- OpenAI только внутри этой ручки.
- Один retry Vision, fallback на `DEFAULT_IMAGE_PROMPT`.
- `lib/ai/garment-schema.ts`, `lib/ai/prompts.ts` — без нового сервисного слоя.

---

Когда будет зелёный свет на рост — открыть этот файл и реализовать по пунктам, не ломая текущий рабочий pipeline.
